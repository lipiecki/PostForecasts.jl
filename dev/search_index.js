var documenterSearchIndex = {"docs":
[{"location":"datasets/#Datasets","page":"Datasets","title":"Datasets","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"PostForecasts.jl ships with two datasets of point forecasts for testing the functionality of the package, the detailed description along with the source is provided below.","category":"page"},{"location":"datasets/#EPEX","page":"Datasets","title":"EPEX","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"The EPEX dataset consists of hourly forecasts of wholesale electricity prices in Germany, as well as the corresponding day-ahead point forecasts computed by Lipiecki et al. (2024) using a LASSO-Estimated AutoRegressive (LEAR) model (Lago et al., 2021). The regressors used in the LEAR model include: ","category":"page"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"historical prices of electricity (various lags), \nday-ahead predictions of the system-wide load,  \nday-ahead predictions of wind and solar generation.","category":"page"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"The parameters are estimated separately for each of the 4 training window lengths, i.e., 56, 84, 1092 and 1456 most recent days, and employ cross-validation for selecting a regularization penalty. The dataset is partitioned into 24 time series corresponding to different hours of the day and spans a 5-year period (2019-2023). The following snippet loads the PointForecasts of EPEX prices for the 20-th trading hour of the day-ahead market (19:00):","category":"page"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"pf::PointForecasts = loaddata(:epex20)","category":"page"},{"location":"datasets/#PANGU","page":"Datasets","title":"PANGU","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"The PANGU dataset contains forecasts from the Pangu-Weather model, computed by Bülte et al. (2024). The model is trained on 39 years of ERA5 reanalysis data from 1979–2017. The dataset consists of 5 weather variables (listed below) for Wrocław, Poland between 2018 and 2022.","category":"page"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"U10: u-component of 10-m wind speed\nV10: v-component of 10-m wind speed\nT2M: temperature at 2m\nT850: temperature at 850 hPa\nZ500: geopotential height at 500 hPa.","category":"page"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"One model run is initialized each day at midnight and used to forecast the variables for up to 186 hours ahead, with 6-hour resolution. The dataset is partitioned into 32 files, which correspond to different forecasting horizons (lead times). The verifying observations are sourced from the ERA5 reanalysis model. The following snippet loads the PointForecasts of temperature at 850 hPa with a lead time of 24 hours:","category":"page"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"pf::PointForecasts = loaddata(:pangu24t850)","category":"page"},{"location":"datasets/#Acknowledgements","page":"Datasets","title":"Acknowledgements","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"We thank: ","category":"page"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"Sebastian Lerch from KIT for preparing the PANGU dataset of weather forecasts for Wrocław\nBartosz Uniejewski for generating LEAR forecasts of electricity prices for the EPEX dataset","category":"page"},{"location":"averaging/#Forecast-Averaging","page":"Averaging forecasts","title":"Forecast Averaging","text":"","category":"section"},{"location":"averaging/#Averaging-schemes","page":"Averaging forecasts","title":"Averaging schemes","text":"","category":"section"},{"location":"averaging/","page":"Averaging forecasts","title":"Averaging forecasts","text":"To exploit the strong predictive performance of combining predictions from different forecasting models, PostForecasts.jl provides averaging schemes for both point and probabilistic forecasts:","category":"page"},{"location":"averaging/#PostForecasts.average","page":"Averaging forecasts","title":"PostForecasts.average","text":"average(pf; agg::Symbol=:mean)\n\nAverage the pool of point pred from pf. Return PointForecasts containing averaged forecasts, keyword argument agg specifies whether to average using simple mean (:mean) or median (:median).\n\nMethods\n\naverage(pf::PointForecasts) to average the pool of forecasts in pf\naverage(pfs::AbstractVector{<:PointForecasts} to average all individual forecasts from every PointForecasts in pfs\ncalling with multiple PointForecasts objects as consecutive arguments, e.g. average(pf1, pf2, pf3), is equivalent to average([pf1, pf2, pf3])\n\n\n\n\n\n","category":"function"},{"location":"averaging/#PostForecasts.qaverage","page":"Averaging forecasts","title":"PostForecasts.qaverage","text":"qaverage(qfs::AbstractVector{<:QuantForecasts})\n\nAverage probabilistic predictions from qfs by averaging the quantiles.\n\nThe function qaverage can also be called by passing QuantForecasts objects as consecutive arguments, e.g. qaverage(qf1, qf2, qf3) is equivalent to qaverage([qf1, qf2, qf3]).\n\nReturn QuantForecasts containing quantile predictions at the same quantile levels as QuantForecasts in qfs.\n\n\n\n\n\n","category":"function"},{"location":"averaging/#PostForecasts.paverage","page":"Averaging forecasts","title":"PostForecasts.paverage","text":"paverage(qfs::AbstractVector{<:QuantForecasts}[; quantiles])\n\nAverage probabilistic predictions from qfs by averaging the distributions across probability.\n\nReturn QuantForecasts containing predictions of specified quantiles:\n\nquantiles::AbstractVector{<:AbstractFloat}: vector of probabilities\nquantiles::AbstractFloat: a single probability value\nquantiles::Integer: number of equidistant probability values (e.g. 99 for percentiles).\n\nThe function paverage can also be called by passing QuantForecasts objects as consecutive arguments, e.g. paverage(qf1, qf2, qf3) is equivalent to paverage([qf1, qf2, qf3]).\n\nIf quantiles argument is not provided, the function will default to the quantiles of the first QuantForecasts in qfs.\n\n\n\n\n\n","category":"function"},{"location":"models/#Models","page":"Models","title":"Models","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"PostForecasts.jl currently provides four models for handling postprocessing of point predictions into probabilistic forecasts: ","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Normal error distribution\nConformal Prediction (and Historical Simulation)\nIsotonic Distributional Regression\nQuantile Regression","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Every model belongs to the PostModel supertype. Models that work exclusively with a single point forecast as a regressor are of type UniPostModel, while models that support multiple regressors are of type MultiPostModel.","category":"page"},{"location":"models/#Normal-error-distribution","page":"Models","title":"Normal error distribution","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"The naive model for probabilistic forecasting, which assumes normally distributed errors of point forecasts.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"The predictive distribution conditional on point forecast haty is a Gaussian mathcalN(haty + mu sigma), where mu and sigma are mean and sample standard deviation of errors in the training window.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"The tau-th quantile conditional on haty of such parameterized distribution can be obtained via an analytic expression:","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"hatq_tauhaty = haty + mu + sigma sqrt2 cdot texterf^-1 (2tau - 1)","category":"page"},{"location":"models/#PostForecasts.Normal","page":"Models","title":"PostForecasts.Normal","text":"Normal([type::Type{F}=Float64]; zeromean::Bool=false) where {F<:AbstractFloat}\n\nCreates a Normal{F}<:UniPostModel{F}<:PostModel{F} model for normal error distribution. Optional keyword argument zeromean specifies whether to assume a zero mean.\n\n\n\n\n\n","category":"type"},{"location":"models/#PostForecasts.getmean","page":"Models","title":"PostForecasts.getmean","text":"getmean(m::Normal)\n\nReturn the mean of the distribution from model m. \n\n\n\n\n\n","category":"function"},{"location":"models/#PostForecasts.getstd","page":"Models","title":"PostForecasts.getstd","text":"getstd(m::Normal)\n\nReturn the standard deviation of the distribution from model m.\n\n\n\n\n\n","category":"function"},{"location":"models/#Conformal-prediction-and-historical-simulation","page":"Models","title":"Conformal prediction and historical simulation","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"Conformal Prediction (CP) is a machine learning framework for computing prediction intervals based on the outputs of an arbitrary point forecasting model. The implemented method corresponds to inductive conformal prediction (Papadopoulos et al., 2002) and is analogous to the approach of Kath and Ziel (2021). ","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"In the training step, the non-conformity scores lambda_i are calculated on the training set (haty_i y_i)_iintexttraining window as lambda_i = haty_i - y_i.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"In the prediction step, the tau-th quantile conditional on haty_t is obtained by shifting the prediction by an appropriate sample quantile of non-conformity scores:","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"hatq_tauhaty = haty - mathbf1_tau  05 Q_1 - 2tau(lambda) + mathbf1_tau  05 Q_2tau - 1(lambda)","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"where Q_alpha(lambda) is the alpha-th sample quantile of non-conformity scores from the training window. Although the intervals in the form of haty - Q_alpha(lambda) haty +Q_alpha(lambda) are valid alpha prediction intervals without any requirements on the underlying distribution, translating them into quantiles requires the assumption of symmetrically distributed errors.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"However, it is also possible to use conformal prediction to obtain non-symmetric distributions, by using non-absolute errors lambda_i = haty_i - y_i. Then, in the prediction step tau-th quantile conditional on haty_t is computed as:","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"hatq_tauhaty = haty + Q_tau(lambda)","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"the method that predates conformal prediction and is widely known as Historical Simulation (HS) (Hendricks, 1996).","category":"page"},{"location":"models/#PostForecasts.CP","page":"Models","title":"PostForecasts.CP","text":"CP([type::Type{F}=Float64,] n::Integer[; abs::Bool=true]) where {F<:AbstractFloat}\n\nCreates a CP{F}<:UniPostModel{F}<:PostModel{F} model for conformal prediction that stores the non-conformity scores of n observations. Optional keyword argument abs specifies whether to use absolute errors.\n\n\n\n\n\n","category":"type"},{"location":"models/#PostForecasts.getscores","page":"Models","title":"PostForecasts.getscores","text":"getscores(m::CP)\n\nReturn a vector of non-conformity score values from model m.\n\n\n\n\n\n","category":"function"},{"location":"models/#Isotonic-distributional-regression","page":"Models","title":"Isotonic distributional regression","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"Isotonic Distributional Regression (IDR; Henzi et al., 2021) has been recently introduced as a novel nonparametric method for estimating distributions that are isotonic in the regressed variable, which means that the quantiles of such distributions are non-decreasing w.r.t the regressor. In the training step, n observations (haty_i y_i)_i in texttraining window are first sorted to be ascending in haty_i. Then, n conditional distributions hatF_i(z) = hatF(zx_i) are obtained by solving the following min-max problem via abridged pool-adjacent-violators algorithm:","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"hatF_i(z) = min_k=1i max_j=kn frac1j-k+1sum_l=k^j mathbb1y_l  z","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"where z in (y_i)_i in texttraining window To obtain conditional distribution for any hatyinmathbbR, the obtained distribution functions are interpolated","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"hatF(zhaty) = frachaty-haty_ihaty_i+1 - haty_ihatF_i(z) + frachaty_i+1 - hatyhaty_i+1 - haty_i hatF_i+1(z)","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"If haty  haty_1 or haty  haty_n, we set hatF(zhaty) to hatF_1(z) or hatF_n(z), respectively. Finally, since ProbcastSeries stores predictive distributions in the form of quantiles, we determine quantiles at specified levels as","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"hatq_tauhaty = minz  hatF(zhaty) geq tau","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"The multivariate version of IDR is not supported, but ForecastSeries containing multiple forecasts can be used as input for computing ProbcastSeries. In such a case, multiple univariate IDR models are estimated and the resulting distributions functions hatF(z) are averaged. Since z is limited to true values of the timeseries in training window, the distributions resulting from estimated IDRs are defined at the exact same points, which allows to efficiently and precisely compute the average across probability. ","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"The implemented IDR estimation uses abridged pool-adjacent-violators algorithm introduced by Henzi et al. (2022).","category":"page"},{"location":"models/#PostForecasts.IDR","page":"Models","title":"PostForecasts.IDR","text":"IDR([type::Type{F}=Float64,] n::Integer, r::Integer) where {F<:AbstractFloat}\n\nCreates an IDR{F}<:MultiPostModel{F}<:PostModel{F} model for isotonic distributional regression to be trained on n observations with r forecasts (regressors).\n\n\n\n\n\n","category":"type"},{"location":"models/#PostForecasts.getcdf","page":"Models","title":"PostForecasts.getcdf","text":"getcdf(m::IDR [, r])\n\nReturn a vector of cumulative distribution function values from model m. Optional argument r::Integer = 1 corresponds to the regressor index.\n\n\n\n\n\n","category":"function"},{"location":"models/#PostForecasts.getx","page":"Models","title":"PostForecasts.getx","text":"getx(m::IDR [, r])\n\nReturn a vector of regressor values from model m on which cumulative distribution function is defined. Optional argument r::Integer = 1 corresponds to the regressor index.\n\n\n\n\n\n","category":"function"},{"location":"models/#PostForecasts.gety","page":"Models","title":"PostForecasts.gety","text":"gety(m::IDR)\n\nReturn a vector of response values from model m on which cumulative distribution function is defined.\n\n\n\n\n\n","category":"function"},{"location":"models/#Quantile-regression","page":"Models","title":"Quantile regression","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"Quantile Regression Averaging (QRA; Nowotarski and Weron, 2014) is a well-established method in for obtaining probabilistic forecasts of electricity prices and load. It learns conditional quantiles as linear combination of m point forecasts:","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"hatq_tauhaty^(1)  haty^(m) = beta^(tau)_0 + beta^(tau)_1haty^(1) +  + beta^(tau)_mhaty^(m)","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"The coefficients beta^(tau)_0m are selected to minimize the pinball loss on the training window and estimated by solving a linear programming problem. For this task, Probcasts.jl employs JuMP.jl and HiGHS.jl packages. Different LP solvers compatible with JuMP can be used, but the constructor defaults to an open source HiGHS.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Apart from the standard QRA introduced by Nowotarski and Weron (2014), PostForecasts.jl allows to readily compute Quantile Regression Machine (QRM; Marcjasz et al., 2020) and Quantile Regression with probability or quantile averaging (Uniejewski et al., 2019). See Different flavors of quantile regression for details.","category":"page"},{"location":"models/#PostForecasts.QR","page":"Models","title":"PostForecasts.QR","text":"QR([type::Type{F}=Float64,] n::Integer, r::Integer, prob::Union{AbstractFloat, AbstractVector{<:AbstractFloat}}) where {F<:AbstractFloat}\n\nCreates a QR{F}<:MultiPostModel{F}<:PostModel{F} model for quantile regression to be trained on n observations with r forecasts (regressors), fitting quantiles at probabilities specified by prob.\n\n\n\n\n\n","category":"type"},{"location":"models/#PostForecasts.getweights","page":"Models","title":"PostForecasts.getweights","text":"getweights(m::QR)\n\nReturn a copy of the weight matrix from model m.\n\n\n\n\n\n","category":"function"},{"location":"models/#PostForecasts.getquantprob","page":"Models","title":"PostForecasts.getquantprob","text":"getquantprob(m::QR)\n\nReturn a copy of the vector of probabilities corresponding to the quantiles from model m.\n\n\n\n\n\n","category":"function"},{"location":"models/#Regularized-quantile-regressions","page":"Models","title":"Regularized quantile regressions","text":"","category":"section"},{"location":"models/#PostForecasts.iQR","page":"Models","title":"PostForecasts.iQR","text":"iQR(args...)\nCreate an isotonic quantile regression model, constraining the weights to be non-negative. The arguments `args...` are the same as for `QR`.\n\n\n\n\n\n","category":"function"},{"location":"models/#PostForecasts.LassoQR","page":"Models","title":"PostForecasts.LassoQR","text":"LassoQR([type::Type{F}=Float64,] n::Integer, r::Integer, prob::Union{AbstractFloat, AbstractVector{<:AbstractFloat}}, lambda::Union{AbstractFloat, AbstractVector{<:AbstractFloat}}) where {F<:AbstractFloat}\n\nCreates a LassoQR{F}<:MultiPostModel{F}<:PostModel{F} model for lasso quantile regression with regularization strength lambda to be trained on n observations with r forecasts (regressors), fitting quantiles at probabilities specified by prob.\n\nIf lambda is a vector, the optimal regularization strength will be selected using the Bayesian Information Criterion (BIC) during every training, separately for each quantile.\n\nBy default, lambda is specified by the package constant LAMBDA = [0.001, 0.01, 0.1, 1.0, 10.0]. It can be modified with the setlambda method. \n\n\n\n\n\n","category":"type"},{"location":"models/#PostForecasts.setlambda","page":"Models","title":"PostForecasts.setlambda","text":"Set the values of the package constant LAMBDA to be equal to lambda.\n\n\n\n\n\n","category":"function"},{"location":"models/#PostForecasts.getlambda","page":"Models","title":"PostForecasts.getlambda","text":"Get the values stored in the package constant `LAMBDA`.\n\n\n\n\n\n","category":"function"},{"location":"models/#Training-and-prediction","page":"Models","title":"Training and prediction","text":"","category":"section"},{"location":"models/#PostForecasts.train","page":"Models","title":"PostForecasts.train","text":"train(m, X::AbstractVecOrMat{<:Number}, Y::AbstractVector{<:Number})\n\nCalibrate the model m on the covariates X and responses Y.\n\nIn general, X should be a matrix, which columns correspond to respective regressors. The number of regressors must match the specification of the model.\n\nFor m::UniPostModel, X can be a vector, if it is a matrix with multiple columns, they will be averaged before training.\n\n\n\n\n\n","category":"function"},{"location":"models/#PostForecasts.predict","page":"Models","title":"PostForecasts.predict","text":"predict(m, input, quantiles)\n\nPredict the specified quantiles of the predictive distribution from model m::PostModel{F} conditional on input.\n\nArgument types\n\ninput can be of type Number or AbstractVector{<:Number}\nquantiles can be of type AbstractFloat (to return a single prediction) or AbstractVector{<:AbstractFloat} (to return a vector of predictions)\n\nNote\n\nFor m::QR, omitting quantiles argument defaults to using all levels specified in model m, which is recommended. Calling predict(m::QR, input, quantiles) will first match each quantile to the levels specified in m, leading to worse performance. The quantile predictions from QR are sorted to avoid crossing (sorting only includes the levels for which predict was called).\n\n\n\n\n\n","category":"function"},{"location":"models/#PostForecasts.predict!","page":"Models","title":"PostForecasts.predict!","text":"predict!(m, output, input, quantiles)\n\nIn-place version of predict that stores the results in the output::AbstractVector{<:AbstractFloat} vector.\n\nArgument types\n\ninput can be of type Number or AbstractVector{<:Number}\nquantiles needs to be of type AbstractVector{<:AbstractFloat}\n\nNote\n\nFor m::QR, quantiles argument is ignored and can be ommited in the function call. The quantile predictions from QR are automatically sorted to avoid crossing.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Utilities","page":"Utilities","title":"Utilities","text":"","category":"section"},{"location":"utils/","page":"Utilities","title":"Utilities","text":"A place to store useful functions that didn't fit elsewhere","category":"page"},{"location":"utils/#PostForecasts.getmodel","page":"Utilities","title":"PostForecasts.getmodel","text":"getmodel([::Type{<:AbstractFloat}=Float64,] ::Val, params...)\n\nHelper function that dispatches the model based on the model name passed as Val.\n\nAvailable methods\n\ngetmodel([type,] Val(:qra), n, m, prob) for Quantile Regression Averaging\ngetmodel([type,] Val(:cp), n) for Conformal Prediction\ngetmodel([type,] Val(:hs), n) for Conformal Prediction Prediction with non-symmetric errors (a.k.a. Historical Simulation)\ngetmodel([type,] Val(:idr), n, m) for Isotonic Distributional Regression\ngetmodel([type,] Val(:normal)) for Normal distribution of errors\ngetmodel([type,] Val(:zeronormal)) for Normal distribution of errors with fixed mean equal to 0\n\nwhere n is the length of the training window, m is the number of regressors and prob is the probability (scalar value or vector).\n\nReturn an appropriate PostModel.\n\n\n\n\n\n","category":"function"},{"location":"utils/#PostForecasts.nreg","page":"Utilities","title":"PostForecasts.nreg","text":"nreg(m::PostModel)\n\nReturn the number of regressors of model m.\n\n\n\n\n\n","category":"function"},{"location":"utils/#PostForecasts.matchwindow","page":"Utilities","title":"PostForecasts.matchwindow","text":"matchwindow(m::PostModel, window::Integer)\n\nReturn true if window matches the specification of model m, otherwise return false.\n\n\n\n\n\n","category":"function"},{"location":"utils/#PostForecasts.checkmatch","page":"Utilities","title":"PostForecasts.checkmatch","text":"checkmatch(fs::AbstractVector{T}; checkpred::Bool=false) where T<:Union{PointForecasts, QuantForecasts}\n\nCheck if Forecasts in fs correspond to the same timeseries, i.e.:\n\nall their identifiers match\nall their observations match.\n\nAdditionally, provided that checkpred=true, check if:\n\ntheir number of forecasts match\ntheir probabilities match.\n\nThe function checkmatch can also be called by passing PointForecasts or QuantForecasts objects as consecutive arguments, e.g. checkmatch(f1, f2, f3) is equivalent to checkmatch([f1, f2, f3]).\n\nReturn true or throw an ArgumentError if any of the requirements above is not met.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#Forecasts","page":"Types","title":"Forecasts","text":"","category":"section"},{"location":"forecasts/","page":"Types","title":"Types","text":"To make working with forecasts easy and user-friendy, PostForecasts.jl introduces the Forecasts supertype that spans PointForecasts and QuantForecast types.","category":"page"},{"location":"forecasts/#PointForecasts","page":"Types","title":"PointForecasts","text":"","category":"section"},{"location":"forecasts/","page":"Types","title":"Types","text":"PointForecasts is a type designed for storing the series of point predictions (single predictions or prediction pools), along with the observations and identifiers (timestamps). The package provides functions for building PointForecasts objects from delimited files, averaging point forecasts and calculating error measures.","category":"page"},{"location":"forecasts/#PostForecasts.PointForecasts","page":"Types","title":"PostForecasts.PointForecasts","text":"PointForecasts(pred::AbstractVecOrMat{F}, obs::AbstractVector{F}[, id::AbstractVector{I}]) where {F<:AbstractFloat, I<:Integer}\n\nCreate PointForecasts{F, I} for storing the series of point predictions, along with the observations and identifiers.\n\nThe shape of pred should be such that pred[t, i] is the prediction for time t from the forecaster i.\n\nIf id is not provided, it will default to 1:length(obs).\n\n\n\n\n\n","category":"type"},{"location":"forecasts/#QuantForecasts","page":"Types","title":"QuantForecasts","text":"","category":"section"},{"location":"forecasts/","page":"Types","title":"Types","text":"QuantForecasts is a type designed for storing the series of probabilistic predictions, represented as quantiles of predictive distribution corresponding to probability levels, along with the observations and identifiers (timestamps). The package provides functions for computing probabilstic forecasts from PointForecasts objects, averaging distributions across quantiles or probabilities, and evaluating probabilistic forecasts.","category":"page"},{"location":"forecasts/#PostForecasts.QuantForecasts","page":"Types","title":"PostForecasts.QuantForecasts","text":"QuantForecasts(pred::AbstractMatrix{F}, obs::AbstractVector{F}[, id::AbstractVector{I}, prob::Union{F, AbstractVector{F}}]) where {F<:AbstractFloat, I<:Integer}\n\nCreate QuantForecasts{F, I} for storing the series of probabilistic predictions, represented as quantiles of predictive distribution at specified probabilities, along with the observations and identifiers.\n\nThe shape of pred should be such that pred[t, i] is the prediction for time t of the prob[i]-quantile.\n\nIf id is not provided, it will default to 1:length(obs). If prob is not provided, it will default to size(pred, 2) equidistant quantiles.\n\n\n\n\n\n","category":"type"},{"location":"forecasts/#Position-based-indexing-and-slicing","page":"Types","title":"Position-based indexing and slicing","text":"","category":"section"},{"location":"forecasts/","page":"Types","title":"Types","text":"PointForecasts and QuantForecasts support position-based indexing and slicing. Accessing a series with a scalar index results in a named tuple, while slicing creates a new Forecasts object built from pred, observations and identifiers stored at respective indices.","category":"page"},{"location":"forecasts/","page":"Types","title":"Types","text":"pf = loaddata(:epex1);\nfirstday = pf[1]\n#(pred = [27.640966097698737, 24.423563275081627, 23.54144377224293, 25.061033846927558], obs = 10.07, id = 20190101)\nfirstweek = pf[1:7]\n#PointForecasts{Float64, Int64} with a pool of 4 forecasts at 7 timesteps, between 20190101 and 20190107","category":"page"},{"location":"forecasts/#Label-based-indexing-and-slicing","page":"Types","title":"Label-based indexing and slicing","text":"","category":"section"},{"location":"forecasts/","page":"Types","title":"Types","text":"Since PointForecasts and QuantForecasts objects have id field storing an integer identifier for every timestep, it is posibble to access the elements by providng their identifier values. Use () for label-based indexing and slicing. Analogously to positional indices, providing a single label results in a named tuple, while a vector creates a new Forecasts object. Additionally, you can provide two labels, (id1, id2), to return Forecasts starting at the timestep with identifier id1 and ending at the timestep with identifier id2.","category":"page"},{"location":"forecasts/","page":"Types","title":"Types","text":"pf = loaddata(:epex1);\nfirstday = pf(20190101)\n#(pred = [27.640966097698737, 24.423563275081627, 23.54144377224293, 25.061033846927558], obs = 10.07, id = 20190101)\nfirstweek = pf([20190101, 20190102, 20190103, 20190104, 20190105, 20190106, 20190107])\n#PointForecasts{Float64, Int64} with a pool of 4 forecasts at 7 timesteps, between 20190101 and 20190107\nfirstweek2 = pf(20190101, 20190107) # same as `firstweek`\n#PointForecasts{Float64, Int64} with a pool of 4 forecasts at 7 timesteps, between 20190101 and 20190107","category":"page"},{"location":"forecasts/#Methods","page":"Types","title":"Methods","text":"","category":"section"},{"location":"forecasts/#PostForecasts.findindex","page":"Types","title":"PostForecasts.findindex","text":"findindex(f::Forecasts, i::Integer)\n\nReturn the index of f, for which the element of field id equals i.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.couple","page":"Types","title":"PostForecasts.couple","text":"couple(fs::AbstractVector{<:T}) where T<:Union{PointForecasts, QuantForecasts}\n\nMerge elements of fs into a single Forecasts object.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.decouple","page":"Types","title":"PostForecasts.decouple","text":"decouple(f:<Forecasts})\n\nReturn a vector of PointForecasts or QuantForecasts objects, where each element contains an individual forecast series from f.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.npred","page":"Types","title":"PostForecasts.npred","text":"npred(f::Forecasts)\n\nReturn the number of point forecasts in f::PointForecasts or the number of forecasted quantiles in f::QuantForecasts.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.setpred","page":"Types","title":"PostForecasts.setpred","text":"setpred(f::Forecasts, t::Integer, i::Integer, val::AbstractFloat)\n\nSet the element of field f.pred at indices t, i to val.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.getpred","page":"Types","title":"PostForecasts.getpred","text":"getpred(f::Forecasts[, T, I])\n\nReturn the copy of predictions from f. \n\nProvide optional argument T::Union{Integer, AbstractVector{<:Integer}} to get predictions at specified time indices.\n\nAdditionally, provide I::Union{Integer, AbstractVector{<:Integer}} to get predicitons at specified forecast indices.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.getobs","page":"Types","title":"PostForecasts.getobs","text":"getobs(f::Forecasts[, T])\n\nReturn the copy of observations from f. \n\nProvide optional argument T::Union{Integer, AbstractVector{<:Integer}} to get observations at specified time indices.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.getid","page":"Types","title":"PostForecasts.getid","text":"getid(f::Forecasts[, T])\n\nReturn the copy of identifiers from f. \n\nProvide optional argument T::Union{Integer, AbstractVector{<:Integer}} to get identifiers at specified time indices.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.getprob","page":"Types","title":"PostForecasts.getprob","text":"getprob(qf::QuantForecasts[, I])\n\nReturn the copy of probabilities from qf. \n\nProvide optional argument I::Union{Integer, AbstractVector{<:Integer}} to get probabilities at specified forecast indices.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.viewpred","page":"Types","title":"PostForecasts.viewpred","text":"viewpred(f::Forecasts[, T, I])\n\nReturn the view of predictions from f. \n\nProvide optional argument T::Union{Integer, AbstractVector{<:Integer}} to get predictions at specified time indices.\n\nAdditionally, provide I::Union{Integer, AbstractVector{<:Integer}} to get predicitons at specified forecast indices.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.viewobs","page":"Types","title":"PostForecasts.viewobs","text":"viewobs(f::Forecasts[, T])\n\nReturn the view of observations from f. \n\nProvide optional argument T::Union{Integer, AbstractVector{<:Integer}} to get observations at specified time indices.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.viewid","page":"Types","title":"PostForecasts.viewid","text":"viewid(f::Forecasts[, T])\n\nReturn the view of identifiers from f. \n\nProvide optional argument T::Union{Integer, AbstractVector{<:Integer}} to get identifiers at specified time indices.\n\n\n\n\n\n","category":"function"},{"location":"forecasts/#PostForecasts.viewprob","page":"Types","title":"PostForecasts.viewprob","text":"viewprob(qf::QuantForecasts[, I])\n\nReturn the view of probabilities from qf. \n\nProvide optional argument I::Union{Integer, AbstractVector{<:Integer}} to get probabilities at specified forecast indices.\n\n\n\n\n\n","category":"function"},{"location":"loadsave/#Loading-and-saving-forecasts","page":"Loading and saving forecasts","title":"Loading and saving forecasts","text":"","category":"section"},{"location":"loadsave/","page":"Loading and saving forecasts","title":"Loading and saving forecasts","text":"With PostForecasts.jl You can easily create PointForecasts from delimited files, load and save both PointForecasts and QuantForecast using HDF5 format and play with pre-installed datasets.","category":"page"},{"location":"loadsave/","page":"Loading and saving forecasts","title":"Loading and saving forecasts","text":"To make managing files generated with PostForecasts.jl easier, HDF5 files containing PointForecasts and QuantForecasts are saved with .pointf and .quantf extensions respectively.","category":"page"},{"location":"loadsave/#PostForecasts.loaddata","page":"Loading and saving forecasts","title":"PostForecasts.loaddata","text":"loaddata(dataset::Union{Symbol, AbstractString})\n\nCreate a PointForecasts object from the dataset provided with the package, availabe options include:\n\nepexH, where H is an integer between 1 and 24\npangu'H'u10, where H is an integer between 0 and 186, divisible by 6.\npangu'H'v10, where H is an integer between 0 and 186, divisible by 6.\npangu'H't2m, where H is an integer between 0 and 186, divisible by 6.\npangu'H't850, where H is an integer between 0 and 186, divisible by 6.\npangu'H'z500, where H is an integer between 0 and 186, divisible by 6.\n\nDetails of the datasets are available in documentation.\n\n\n\n\n\n","category":"function"},{"location":"loadsave/#PostForecasts.loaddlm","page":"Loading and saving forecasts","title":"PostForecasts.loaddlm","text":"loaddlm(filepath::AbstractString; kwargs...)\n\nCreate a PointForecasts object from delimited file at filepath.\n\nKeyword Arguments\n\ndelim=',': Specifies the delimitter\nobscol=1: Specifies which column is used for observations\npredcol=nothing: Specifies which columns are used for pred (omit to use all remaining columns)\nidcol=nothing: Specifies which column is used for timestamps (omit to generate timestamps automatically)\ncolnames=false If true, omit the first row of the file.\n\n\n\n\n\n","category":"function"},{"location":"loadsave/#PostForecasts.saveforecasts","page":"Loading and saving forecasts","title":"PostForecasts.saveforecasts","text":"saveforecasts(f::Forecasts, filepath::AbstractString)\n\nSave f to a HDF5 file at filepath with .pointf extension for PointForecasts and .quantf extension for QuantForecasts (extension is added if missing).\n\n\n\n\n\n","category":"function"},{"location":"loadsave/#PostForecasts.loadforecasts","page":"Loading and saving forecasts","title":"PostForecasts.loadforecasts","text":"loadforecasts(filepath::AbstractString)::Forecasts\n\nLoad PointForecasts or QuantForecasts from filepath (.pointf or .quantf extension is required).\n\n\n\n\n\n","category":"function"},{"location":"loadsave/#PostForecasts.loadpointf","page":"Loading and saving forecasts","title":"PostForecasts.loadpointf","text":"loadpointf(filepath::AbstractString)::PointForecasts\n\nLoad PointForecasts from filepath (.pointf extension is added if missing).\n\n\n\n\n\n","category":"function"},{"location":"loadsave/#PostForecasts.loadquantf","page":"Loading and saving forecasts","title":"PostForecasts.loadquantf","text":"loadquantf(filepath::AbstractString)::QuantForecasts\n\nLoad QuantForecasts from filepath (.quantf extension is added if missing).\n\n\n\n\n\n","category":"function"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Below you can find some simple examples of what can be achieved with PostForecasts.jl","category":"page"},{"location":"examples/#Load-and-postprocess-point-forecasts","page":"Examples","title":"Load and postprocess point forecasts","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"In the first example, we show how to load point forecasts from a delimited file and postprocess them using a selected model in PostForecasts.jl. Assume that the file named myforecasts.csv has the following structure: ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"time    real    predA   predB\n1       110.8   118.7   116.0\n2       18.0    114.1   109.2\n3       71.9    82.7    75.0\n...","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"To load and postprocess it, we only need two function calls:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using PostForecasts\npf = loaddlm(\"myforecasts.csv\", delim='\\t', idcol=1, obscol=2, predcol = [3, 4], colnames=true)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"First, we read the file with the loaddlm function, which arguments specify that the file is tab delimited, the identifiers are stored in the first column, the observations in the second, and the predictions in the third and fourth. The last argument informs that the column names are present in the file, so the first row is not parsed into numeric values.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"qf = point2quant(pf, method=:qr, window=100, quantiles=[0.5, 0.9])","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Next, the point2quant function postprocesses the forecasts stored in pf, computes quantile predictions and returns a QuantForecasts object, saved to qf. In the above snippet, the arguments of point2quant specify that quantile regression is used for postprocessing, the length of the calibration window is 100 data points, and that we want to predict the median and the 90th percentile. By default, the postprocessing model is retrained before every prediction using a calibration window of most recent data points. For details on alternative configurations, see the documentation of the point2quant function.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Quantile forecasts qf are now ready to be evaluated, averaged with other forecasts, conformalized, and saved.","category":"page"},{"location":"examples/#Probabilistic-forecasting-of-day-ahead-electricity-prices","page":"Examples","title":"Probabilistic forecasting of day-ahead electricity prices","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"In this example we show how to compute probabilistic forecasts of day-ahead electricity prices from point forecasts stored in the EPEX dataset for all hours of the year 2023, using three different postprocessing schemes – IDR, CP and QRA. See (Lipiecki et al., 2024) for more details on this forecasting task.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The code snippet below first creates a dictionary qf that for each key (corresponding to the postprocessing method) will store a vector of 24 QuantForecasts objects. Then it iterates over the 24 hours of the day, loads the point forecasts and, using each method, generates the probabilistic forecasts of 9 deciles (i.e. 10%, 20%, ..., 90% percentiles) for 2023:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using PostForecasts\n\nmethods = [:idr, :cp, :qr]\nqf = Dict((m => Vector{QuantForecasts}(undef, 24) for m in methods)...)\n\nfor h in 1:24\n    pf = loaddata(Symbol(:epex, h))\n    for m in methods\n        qf[m][h] = point2quant(pf, method=m, window=56, quantiles=9, start=20230101, stop=20231231)\n    end\nend","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Probabilistic forecasts can then be combined, e.g., using vertical distribution averaging by calling paverage:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"qf[:ave] = Vector{QuantForecasts}(undef, 24)\nfor h in 1:24\n    qf[:ave][h] = paverage([qf[m][h] for m in methods])\nend","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"and the CRPS of the individual and the combined predictive distributions can be easily compared:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"println(\"Method \\t| CRPS \")\nprintln(\"-\"^20)\nfor m in [methods..., :ave]\n    println(uppercase(string(m)), \" \\t| CRPS: \", round(sum(crps.(qf[m]))/24, digits=3))\nend","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"which should generate the following output:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Method \t| CRPS \n--------------------\nIDR     | CRPS: 9.752\nCP      | CRPS: 9.822\nQR      | CRPS: 9.986\nAVE     | CRPS: 9.248","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Note that the computations can take some time. While IDR and CP are almost instantaneous, QR is more time-consuming and can take up to a few minutes.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The script corresponding to this example can be found in examples/postprocess.jl.","category":"page"},{"location":"examples/#Different-flavors-of-quantile-regression","page":"Examples","title":"Different flavors of quantile regression","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"There are multiple approaches to applying quantile regression to a pool of point forecasts, here we compare four of them, which can be readily computed using the PostForecasts.jl package.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The code below shows how to compute probabilistic forecasts of day-ahead electricity prices at 7pm for the entire 2021 from point forecasts stored in the EPEX dataset, using four variants of quantile regression and a one-year training window.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using PostForecasts\n\npf = loaddata(:epex20)\npf = pf(20200101, 20211231)\nqf = Dict()","category":"page"},{"location":"examples/#QRA","page":"Examples","title":"QRA","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Quantile Regression Averaging - each point forecast is treated as a separate regressor in a multivariate quantile regression - hatq_tauhaty^(1)  haty^(m) = beta^(tau)_0 + beta^(tau)_1haty^(1) +  + beta^(tau)_mhaty^(m)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"qf[\"QRA\"] = point2quant(pf, method=:qr, window=365, quantiles=9)","category":"page"},{"location":"examples/#QRM","page":"Examples","title":"QRM","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Quantile Regression Machine - point forecasts are averaged and treated as a single regressor in a univariate quantile regression - hatq_tauhaty^(1)  haty^(m) = beta^(tau)_0 + beta^(tau)_1 frac1msum_i=1^mhaty^(i)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"qf[\"QRM\"] = point2quant(average(pf), method=:qr, window=365, quantiles=9)","category":"page"},{"location":"examples/#QRF","page":"Examples","title":"QRF","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Quantile Regression with probability (F) averaging - each point forecast is treated as a regressor of a univariate quantile regression, the output distributions of m quantile regressions are averaged over probabilities","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"qf[\"QRF\"] = paverage(point2quant.(decouple(pf), method=:qr, window=365, quantiles=9))","category":"page"},{"location":"examples/#QRQ","page":"Examples","title":"QRQ","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Quantile Regression with Quantile averaging - each point forecast is treated as a regressor of a univariate quantile regression, the output distributions of m quantile regressions are averaged over quantiles","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"qf[\"QRQ\"] = qaverage(point2quant.(decouple(pf), method=:qr, window=365, quantiles=9))","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Then we can print the resulting CRPS of the computed forecasts:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"println(\"Method \\t| CRPS \")\nprintln(\"-\"^20)\nfor m in [\"QRA\", \"QRM\", \"QRF\", \"QRQ\"]\n    println(m, \"\\t| \", round(crps(qf[m]), digits=3))\nend","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"which should generate the following output:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Method \t| CRPS \n--------------------\nQRA \t| 10.464\nQRM \t| 10.229\nQRF \t| 10.308\nQRQ \t| 10.285","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The script corresponding to this example can be found in examples/quantregs.jl.","category":"page"},{"location":"examples/#Conformalizing-weather-forecasts","page":"Examples","title":"Conformalizing weather forecasts","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"In this example we show how to conformalize quantile forecasts to improve the coverage of predictive distributions of weather variables from the PANGU dataset postprocessed using IDR, and visualize the miscoverage, i.e., the difference between nominal and empirical coverage, with respect to the quantile levels.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"We will first load the dataset (select the target variable and the lead time of point predictions):","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using PostForecasts\n\nvariable = :u10 # u10, c10, t2m, t850 or z500\nleadtime = 24   # between 0 and 186, divisible by 6\n\npf = loaddata(Symbol(:pangu, leadtime, variable))","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Then, using the point2quant function, we compute the quantile forecasts qf for 9 deciles using IDR with a training window of 365 days and calculate its miscoverage with the help of the coverage function:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"qf = point2quant(pf, method=:idr, window=364, quantiles=9)\nmiscoverageIDR = (coverage(qf) - getprob(qf)).*100","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Now, we can conformalize forecasts stored in qf and calculate the miscoverage of conformalized quantiles:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"conformalize!(qf, window=182)\nmiscoverageConformalizedIDR = (coverage(qf) - getprob(qf)).*100","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Note that we used the in-place method conformalize!, which will leave the first 182 unconformalized predictions in qf, ensuring that the we compare the results on the same time period.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Finally, we generate a barplot representing the miscoverage for every forecasted quantile level:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Plots\nplot(xlabel=\"Quantile level (%)\", ylabel=\"Miscoverage (%)\", framestyle=:grid, xticks = 10:10:90)\n\nqf = point2quant(pf, method=:idr, window=365, quantiles=9)\nbar!(getprob(qf).*100, (coverage(qf)-getprob(qf)).*100, linewidth=0, color=colorant\"#bcbddc\", label=\"IDR\") \n\nconformalize!(qf, window=182)\nbar!(getprob(qf).*100, (coverage(qf)-getprob(qf)).*100, linewidth=0, color=colorant\"#756bb1\", label=\"Conformalized IDR\")","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The resulting plots shows that the conformalization helped to significantly decrease the miscoverage of IDR predictions, leading to better calibrated quantile forecasts, especially at extreme levels (0.1 and 0.9): (Image: image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The script corresponding to this example can be found in examples/conformalize.jl.","category":"page"},{"location":"examples/#Supporting-decision-making-on-energy-markets","page":"Examples","title":"Supporting decision making on energy markets","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"To highlight the significance and utility of probabilistic forecasts, let us present a short scenario of trading on day-ahead electricity market.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Consider an energy company that owns a battery and trades in the day-ahead market. Every morning it faces the decision about whether to submit a buy order to charge the battery and a sell order to discharge it at a later hour of the next day, or avoid trading due to adverse market conditions. In this example, we show how probabilistic forecasts can help us identify risky market conditions and prevent losses.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"For simplicity, we focus on two weeks in April 2023 and assume that buy orders are submitted at 3am while sell orders at 7pm. The following snippet shows how to postprocess point predictions from the EPEX dataset to obtain decile forecasts using the IDR:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using PostForecasts\n\npfbuy = loaddata(Symbol(:epex, 4))      # point forecasts for 3am\npfsell = loaddata(Symbol(:epex, 20))    # point forecasts for 7pm\n\nqfbuy = point2quant(pfbuy, method=:idr, window=182, quantiles=9, start=20230408, stop=20230421)\nqfsell = point2quant(pfsell, method=:idr, window=182, quantiles=9, start=20230408, stop=20230421)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"From the decile forecasts we can construct four prediction intervals (PI) centered around the median, i.e., the 5th decile, with confidence levels of 20%, 40%, 60% and 80%. For example, the 20%-PI is obtained by taking the 4th and the 6th deciles, while the 80%-PI by taking the 1st and the 9th. To visualize the results, we can plot the median price forecasts, the PIs and the observed prices at 3am and 7pm (helper functions for plotting are available in src/examples/plotting.jl):","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# load plot_obs!, plot_quantile! and plot_intervals!\ninclude(\"plotting.jl\")\n\npfbuy = loaddata(Symbol(:epex, 4))      # point forecasts for 3am\npfsell = loaddata(Symbol(:epex, 20))    # point forecasts for 7pm\n\nqfbuy = point2quant(pfbuy, method=:idr, window=182, quantiles=9, start=20230408, stop=20230421)\nqfsell = point2quant(pfsell, method=:idr, window=182, quantiles=9, start=20230408, stop=20230421)\n\nplt = plot(legend=:bottom, xlabel=\"Days\", ylabel=\"Price (EUR/MWh)\", xticks=1:14, framestyle=:box) \nplot_intervals!(plt, qfsell, color=1)\nplot_intervals!(plt, qfbuy, color=3)\nplot_quantile!(plt, qfsell, 5, color=1)\nplot_quantile!(plt, qfbuy, 5, color=3)\nplot_obs!(plt, qfsell, color=1, label=\"Sell price\")\nplot_obs!(plt, qfbuy, color=3, label=\"Buy price\")","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Clearly, on the third day the upper quantiles of prices for 3am significantly overlap the lower quantiles of prices for 7pm. This indicates that the buy price is quite likely to be higher than the sell price, so the trading strategy carries substantial risk. Indeed, the actual price at 7pm (rightarrow red dot) was lower than at 3am (rightarrow green dot) for that day, so trading would lead to incurring a loss. ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This short example showcases how probabilistic forecasts can aid decision making with richer information about possible outcomes. To read about the strategies for battery-based trading on electricity markets and their economic evaluation, see the contributions of Nitka and Weron (2023) and Maciejowska et al. (2023).","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The script corresponding to this example can be found in examples/trading.jl.","category":"page"},{"location":"shapley/#Shapley-values-and-contributions-to-the-ensemble","page":"Shapley values and ensemble contributions","title":"Shapley values and contributions to the ensemble","text":"","category":"section"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"When averaging multiple predicitons, a question arises of what each forecaster brings to the table. To answer that, we propose to use Shapley values, following machine learning methods like SHapley Additive exPlanations (SHAP; Lundberg and Lee, 2017), Loss SHapley Additive exPlanations (LossSHAP; Lundberg et al., 2020) and Shapley Additive Global importancE (SAGE; Covert et al., 2020). Shapley values were originally developed to fairly distribute total wins (rightarrow predictive power) among players (rightarrow ensemble components) in a cooperative game based on their individual contributions. In our approach, we consider a coalition game v_x(S), defined as","category":"page"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"v_x(S) = -L(textAve_x(S) x)","category":"page"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"where S is a non-empty subset of forecasters (players), L is a loss function and textAve_x(S) is the prediction of x obtained by averaging forecasts from S. Shapley values for the game v_x(S) are analogous to LossSHAP of model textAve_x(S), while their mean over a testing period is a counterpart of SAGE. However, we consider simple averaging methods for which marginal contributions can be calculated directly, without resorting to approximation algorithms required by SHAP, LossSHAP and SAGE.","category":"page"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"For the game v_x(S) and a set of N players (forecasters), Shapley value phi_i of forecaster i is given by","category":"page"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"phi_i = frac1N sum_S in P(N backslash i) binomN-1S^-1leftv_x(S cup i) - v_x(S)right","category":"page"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"The sum above extends over the entire powerset P(N backslash i), including the empty set varnothing. Let us diverge from this standard definition by omitting the empty coalition and defining Shapley contributions Phi_i as","category":"page"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"Phi_i = frac1Nsum_S in P(N backslash i)backslashvarnothing binomN-1S^-1leftv_x(S cup i) - v_x(S)right","category":"page"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"As a result, Phi discounts the accuracy of individual forecasters, i.e. Phi_i = phi_i - frac1N(v_x(i) - v_x(varnothing)) and hence Shapley contributions sum up to the accuracy gained from averaging, i.e. the difference between the accuracy of the ensemble average and the average accuracy of individual ensemble components:","category":"page"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"sum_iin NPhi_i = v_x(N) - frac1Nsum_i in Nv_x(i)","category":"page"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"Although Phi differ from standard Shapley values, they remain to be a fair allocation, in a sense that Phi_i  Phi_j iff v_x(i)  v_x(j) for N=ij. Furthermore, the properties of symmetry, linearity and null-player also hold for Shapley values Phi.","category":"page"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"PostForecasts.jl provides shapley function that allows to calculate Shapley values for both point and probabilstic forecats using arbitrary averaging method and payoff function. Returned values are averages over the forecasted period.","category":"page"},{"location":"shapley/#PostForecasts.shapley","page":"Shapley values and ensemble contributions","title":"PostForecasts.shapley","text":"shapley(fs::AbstractVector{<:T}, agg::Function, payoff::Function[, ∅::AbstractFloat]) where T<:Union{PointForecasts, QuantForecasts}\n\nCalculate Shapley values of forecasters in fs, using specified aggregation function and payoff function.\n\nOptional argument ∅ is the payoff value for an empty coalition. If not provided, empty coalition is excluded from calculations.\n\nReturn a vector of Shapley values correspinding to each forecaster in fs.\n\n\n\n\n\n","category":"function"},{"location":"shapley/","page":"Shapley values and ensemble contributions","title":"Shapley values and ensemble contributions","text":"The function agg passed to shapley should be of the signature ::Vector{<:Forecasts{T, I} -> ::Forecasts{T, I}} and payoff function: ::Forecasts{T, I} -> ::Number.","category":"page"},{"location":"postprocess/#Postprocessing","page":"Postprocessing","title":"Postprocessing","text":"","category":"section"},{"location":"postprocess/#From-point-to-probabilistic-forecasts","page":"Postprocessing","title":"From point to probabilistic forecasts","text":"","category":"section"},{"location":"postprocess/","page":"Postprocessing","title":"Postprocessing","text":"Building probabilistic forecasts from point predictions is the core functionality of PostForecasts.jl. The function point2quant turns PointForecasts into QuantForecasts, allowing to easily postprocess point predictions using a selected method, length of the training window and retraining frequency. See Models for details on the available postprocessing methods.","category":"page"},{"location":"postprocess/#PostForecasts.point2quant","page":"Postprocessing","title":"PostForecasts.point2quant","text":"point2quant(pf; method, window, quantiles[, start, stop, retrain])\n\nCompute probabilistic forecast based on pf::PointForecasts using PostModel specified by method::Symbol.\n\nReturn QuantForecasts containing forecasts of specified quantiles:\n\nquantiles::AbstractVector{<:AbstractFloat}: vector of probabilities\nquantiles::AbstractFloat: a single probability value\nquantiles::Integer: number of equidistant probability values (e.g. 99 for percentiles).\n\nAvailable options for method:\n\n:cp for conformal prediction\n:hs for historical simulation\n:idr for isotonic distributional regression\n:qr for quantile regression\n:iqr for isotonic quantile regression\n:lassoqr for lasso quantile regression\n:normal for normal distribution of errors\n:zeronormal for normal distribution of errors with fixed mean equal to 0\n\nOther keyword arguments:\n\nwindow::Integer: the number of past observations used for training the model\nstart::Integer = pf.id[begin + window]: specify the identifier in pf at which quantile forecasts will start (if not provided, the first available will be used)\nstop::Integer = pf.id[end]: specify the identifier in pf at which quantile forecasts will stop (if not provided, the last available will be used)\nretrain::Integer = 1: specify how often to retrain the model. If retrain == 0, the model will be trained only once, otherwise it will be retrained every retrain steps\n\nNote\n\nthe function can also be called with method, window and quantiles as positional arguments\n:qr supports multiple regressors\n:idr partially supports multiple regressors: one isotonic regression is fitted to each forecast and the final predictive distribution is an average of individual distributions\n:cp, :normal and :zeronormal do not support multiple regressors: if pf contains multiple point forecasts, their average will be used for postprocessing\n\n\n\n\n\n","category":"function"},{"location":"postprocess/#Conformalizing-probabilistic-forecasts","page":"Postprocessing","title":"Conformalizing probabilistic forecasts","text":"","category":"section"},{"location":"postprocess/","page":"Postprocessing","title":"Postprocessing","text":"Apart from postprocessing point forecasts, the package offers postprocessing of probabilistic forecasts in a form of conformalization (Romano et al., 2019). Conformalizing quantiles is performed by adjusting the prediction of each quantile according to the formula hatq^(c)_tau = hatq_tau + Q_tau(lambda), where Q_tau(lambda) is the (tau)-th sample quantile of non-conformity scores lambda_i = y_i - hatq_itau from the training window. See an example on Conformalizing weather forecasts.","category":"page"},{"location":"postprocess/#PostForecasts.conformalize","page":"Postprocessing","title":"PostForecasts.conformalize","text":"conformalize(qf::QuantForecasts{F, I}; window::Integer[, start, stop)\n\nPerform conformalization of quantile forecasts provided in qf. Conformalized quantiles will be calculated for observations between the start and stop identifiers in qf. The model is retrained every step on the last window observations.\n\nReturn QuantForecasts with conformalized quantiles.\n\n\n\n\n\n","category":"function"},{"location":"postprocess/#PostForecasts.conformalize!","page":"Postprocessing","title":"PostForecasts.conformalize!","text":"conformalize!(qf::QuantForecasts{F, I}; window::Integer[, start, stop)\n\nIn-place version of conformalize that mutates qf instead of creating a new QuantForecasts.\n\n\n\n\n\n","category":"function"},{"location":"#PostForecasts.jl","page":"Home","title":"PostForecasts.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: image)","category":"page"},{"location":"#Julia-package-for-postprocessing-forecasts","page":"Home","title":"Julia package for postprocessing forecasts","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PostForecasts.jl provides structures and functions that allow to easily postprocess point forecasts into predictive distributions. Postprocessing methods use only the past performance of a given point forecasting model (or ensemble of models) to build probabilistic forecasts conditional on point predictions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"PostForecasts.jl:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Relies on deterministic models for reliable and repeatable results\nDoes not require hyperparameter tuning\nLeverages forecaster diversity via averaging","category":"page"},{"location":"","page":"Home","title":"Home","text":"We believe that following these three principles allowed us to develop a robust tool for computing probabilistic forecasts that combines ease of use, high accuracy, fast results and good interpretability. This makes PostForecasts.jl an attractive choice for both academic and industrial applications.","category":"page"},{"location":"#Quick-start","page":"Home","title":"Quick start","text":"","category":"section"},{"location":"#Dedicated-types","page":"Home","title":"Dedicated types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PostForecasts.jl introduces PointForecasts and QuantForecasts types for storing time series data along with point and probabilistic forecasts respectively.","category":"page"},{"location":"#Postprocessing-models","page":"Home","title":"Postprocessing models","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package provides interface to four selected models for probabilistic forecasting:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Normal:  Normal error distribution\nCP: Conformal Prediction (and Historical Simulation)\nIDR: Isotonic Distributional Regression\nQR: Quantile Regression","category":"page"},{"location":"","page":"Home","title":"Home","text":"All the models belong to the PostModel supertype. They have corresponding train(m, X, Y) methods for calibrating a model m to inputs X and targets Y, and predict(m, input, quantiles) methods that yield the specified quantiles of the predictive distribution from m conditional on input.","category":"page"},{"location":"#Easy-postprocessing","page":"Home","title":"Easy postprocessing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The core functionality of PostForecasts.jl is building probabilistic forecasts from point predictions. For easy postprocessing, use point2quant function to turn PointForecasts into QuantForecasts with one of the implemented models.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In addition to methods for postprocessing point forecasts, the package provides conformalize function, allowing to correct quantile forecasts using historical errors.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PostForecasts.jl is a registered Julia package, to install it just run the following lines in the Julia REPL:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Pkg\njulia> Pkg.add(\"PostForecasts\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Alternatively, you can use the Pkg REPL mode:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add PostForecasts","category":"page"},{"location":"#Citing","page":"Home","title":"Citing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Check out the original software publication on PostForecasts.jl in SoftwareX. If you use the package in your research, then please cite it as:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@article{lipiecki:weron:2025,\n    title = {PostForecasts.jl: A Julia package for probabilistic forecasting by postprocessing point predictions},\n    journal = {SoftwareX},\n    volume = {31},\n    pages = {102200},\n    year = {2025},\n    issn = {2352-7110},\n    doi = {https://doi.org/10.1016/j.softx.2025.102200},\n    author = {Arkadiusz Lipiecki and Rafał Weron}\n}","category":"page"},{"location":"#Research-papers","page":"Home","title":"Research papers","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Below is the list of research papers using PostForecasts.jl:","category":"page"},{"location":"","page":"Home","title":"Home","text":"A. Lipiecki, B. Uniejewski & R. Weron Postprocessing of point predictions for probabilistic forecasting of day-ahead electricity prices: The benefits of using isotonic distributional regression Energy Economics, 139 (2024) 107934\nA. Lipiecki & B. Uniejewski Isotonic Quantile Regression Averaging for uncertainty quantification of electricity price forecasts arXiv.2507.15079 (GitHub)","category":"page"},{"location":"evaluation/#Evaluation-metrics","page":"Evaluation metrics","title":"Evaluation metrics","text":"","category":"section"},{"location":"evaluation/","page":"Evaluation metrics","title":"Evaluation metrics","text":"To evaluate the peformance of both point and probabilistic forecasts, PostForecasts.jl offers methods for calculating popular evaluation metrics.","category":"page"},{"location":"evaluation/#PostForecasts.mae","page":"Evaluation metrics","title":"PostForecasts.mae","text":"mae(pf::PointForecasts)\n\nCalculate Mean Absolute Error of predictions from pf. Return the vector of MAE corresponding to each forecaster.\n\n\n\n\n\n","category":"function"},{"location":"evaluation/#PostForecasts.mape","page":"Evaluation metrics","title":"PostForecasts.mape","text":"mape(pf::PointForecasts; eps=1e-9)\n\nCalculate Mean Absolute Percentage Error of predictions from pf. Return the vector of MAPE corresponding to each forecaster.\n\n\n\n\n\n","category":"function"},{"location":"evaluation/#PostForecasts.smape","page":"Evaluation metrics","title":"PostForecasts.smape","text":"smape(pf::PointForecasts; eps=1e-9)\n\nCalculate Symmetric Mean Absolute Percentage Error of predictions from pf. Return the vector of SMAPE corresponding to each forecaster.\n\n\n\n\n\n","category":"function"},{"location":"evaluation/#PostForecasts.mse","page":"Evaluation metrics","title":"PostForecasts.mse","text":"mse(pf::PointForecasts)\n\nCalculate Mean Squared Error of predictions from pf. Return the vector of MSE corresponding to each forecaster.\n\n\n\n\n\n","category":"function"},{"location":"evaluation/#PostForecasts.pinball","page":"Evaluation metrics","title":"PostForecasts.pinball","text":"pinball(qf::QuantForecasts)\n\nCalculate Pinball Loss over all quantiles in qf. Return the vector of Pinball Loss values corresponding to each quantile. See Gneiting 2011 for more details about Pinball Loss. \n\nNote\n\nAverage Pinball Loss over equidistant quantiles approximates Continuous Ranked Probability Score.\n\n\n\n\n\n","category":"function"},{"location":"evaluation/#PostForecasts.crps","page":"Evaluation metrics","title":"PostForecasts.crps","text":"crps(qf::QuantForecasts)\n\nApproximate Continuous Ranked Probability Score using the Pinball Loss of quantile forecasts in qf, with 2mean(pinball(qf)).\n\nNote\n\nApproximating CRPS with the average Pinball Loss requires a dense grid of equidistant quantiles.\n\n\n\n\n\n","category":"function"},{"location":"evaluation/#PostForecasts.coverage","page":"Evaluation metrics","title":"PostForecasts.coverage","text":"coverage(qf::QuantForecasts)\n\nCalculate empirical coverage of quantile predictions in qf. Return the vector of coverage corresponding to each quantile. \n\n\n\n\n\n","category":"function"}]
}
